{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10297296,"sourceType":"datasetVersion","datasetId":6373493}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Step 1: Importing Basic Libraries ","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sb ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-27T17:54:28.562892Z","iopub.execute_input":"2024-12-27T17:54:28.563156Z","iopub.status.idle":"2024-12-27T17:54:30.725485Z","shell.execute_reply.started":"2024-12-27T17:54:28.563131Z","shell.execute_reply":"2024-12-27T17:54:30.724483Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n# Dataset Integrity VerificationThe SHA-256 hash of the dataset used in this notebook is:f7b7b240b5a2684033844cd61da732003b7e305a62ed523418112fc1de48fdbfThis ensures the dataset's integrity and authenticity\n.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport hashlib\n\n# Loading the dataset\ndf = pd.read_csv(\"/kaggle/input/renewable-energy-usage-in-usa/Renewable energy usage in USA.csv\")\n\n# Converting the DataFrame to a CSV string without the index\ndata_string = df.to_csv(index=False)\n\n# Computing the SHA-256 hash of the dataset\nhash_value = hashlib.sha256(data_string.encode()).hexdigest()\n\n# Printing the hash\nprint(f\"SHA-256 Hash of the Dataset: {hash_value}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T17:55:59.435125Z","iopub.execute_input":"2024-12-27T17:55:59.435481Z","iopub.status.idle":"2024-12-27T17:55:59.516754Z","shell.execute_reply.started":"2024-12-27T17:55:59.435455Z","shell.execute_reply":"2024-12-27T17:55:59.515568Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 3: Displaying Dataset","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T17:58:19.220557Z","iopub.execute_input":"2024-12-27T17:58:19.221080Z","iopub.status.idle":"2024-12-27T17:58:19.262427Z","shell.execute_reply.started":"2024-12-27T17:58:19.221043Z","shell.execute_reply":"2024-12-27T17:58:19.260983Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df.info())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T18:05:36.389298Z","iopub.execute_input":"2024-12-27T18:05:36.389703Z","iopub.status.idle":"2024-12-27T18:05:36.418875Z","shell.execute_reply.started":"2024-12-27T18:05:36.389672Z","shell.execute_reply":"2024-12-27T18:05:36.417546Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 4: Normalizing Data","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\n# Step 1: Selecting all numerical columns\nnumerical_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n\n# Step 2: Excluding 'Year', 'Month', and the target variable (if applicable, e.g., 'Class')\ncolumns_to_exclude = ['Year', 'Month', 'Sector_Commerical', 'Sector_Electric Power', 'Sector_Industrial', 'Sector_Residential',\t'Sector_Transportation']  \ncolumns_to_normalize = [col for col in numerical_cols if col not in columns_to_exclude]\n\n# Step 3: Normalizing the selected columns\nscaler = MinMaxScaler()\ndf[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])\n\n# Displaying the normalized dataset\ndf.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T18:06:01.467409Z","iopub.execute_input":"2024-12-27T18:06:01.467799Z","iopub.status.idle":"2024-12-27T18:06:01.611917Z","shell.execute_reply.started":"2024-12-27T18:06:01.467771Z","shell.execute_reply":"2024-12-27T18:06:01.609422Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 5: EDA ","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Group data by 'Month' and calculate the mean only for numeric columns\nmonthly_trends = df.groupby('Month').mean(numeric_only=True)\n\n# Plotting the monthly trends for specified energy types\nax = monthly_trends[['Hydroelectric Power', 'Geothermal Energy', 'Solar Energy', \n                     'Wind Energy', 'Wood Energy', 'Waste Energy', \n                     'Fuel Ethanol, Excluding Denaturant', 'Biomass Losses and Co-products', \n                     'Conventional Hydroelectric Power', 'Biodiesel']].plot(kind='line', \n                                                                           figsize=(10, 5), \n                                                                           marker='o')\n\nplt.title('Monthly Average Energy Consumption')\nplt.xlabel('Month')\nplt.ylabel('Average Consumption')\n\nplt.text(0.5, 0.5, \"Mohsin Ali Fida's Notebook\", \n         fontsize=30, color='gray', alpha=0.3, \n         ha='center', va='center', rotation=30, transform=ax.transAxes)\n\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T18:13:08.778730Z","iopub.execute_input":"2024-12-27T18:13:08.779192Z","iopub.status.idle":"2024-12-27T18:13:09.184008Z","shell.execute_reply.started":"2024-12-27T18:13:08.779157Z","shell.execute_reply":"2024-12-27T18:13:09.182883Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Selecting only numeric columns\nnumeric_data = df.select_dtypes(include=[np.number])\n\n# Calculating the correlation matrix\ncorrelation_matrix = numeric_data.corr()\n\n# Creating the heatmap\nplt.figure(figsize=(6, 3))\nax = sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n\nplt.title(\"Correlation Matrix\")\n\nplt.text(0.5, 0.5, \"Notebook by Mohsin ALi\", \n         fontsize=30, color='gray', alpha=0.3, \n         ha='center', va='center', rotation=30, transform=ax.transAxes)\n\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T18:13:14.534036Z","iopub.execute_input":"2024-12-27T18:13:14.534412Z","iopub.status.idle":"2024-12-27T18:13:15.408171Z","shell.execute_reply.started":"2024-12-27T18:13:14.534383Z","shell.execute_reply":"2024-12-27T18:13:15.407098Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T18:19:13.603533Z","iopub.execute_input":"2024-12-27T18:19:13.603940Z","iopub.status.idle":"2024-12-27T18:19:13.635987Z","shell.execute_reply.started":"2024-12-27T18:19:13.603909Z","shell.execute_reply":"2024-12-27T18:19:13.634791Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Checking if the Season columns are one-hot encoded and decode to a categorical column\nif 'Season_Spring' in data.columns:\n    # Decode one-hot columns back to a single categorical column\n    data['Season'] = data[['Season_Spring', 'Season_Summer', 'Season_Winter']].idxmax(axis=1)\n    # Map the one-hot column names to season names\n    data['Season'] = data['Season'].map({\n        'Season_Spring': 'Spring',\n        'Season_Summer': 'Summer',\n        'Season_Winter': 'Winter'\n    })\n\n# Defining a custom color palette with dark green, dark red, and dark blue\ncustom_palette = {'Spring': '#2ca02c', 'Summer': '#d62728', 'Winter': '#1f77b4'}\n\n# Plotting the boxplot with the custom color palette\nplt.figure(figsize=(7, 5))\nax = sns.boxplot(data=data, x='Season', y='Total Renewable Energy', palette=custom_palette)\n\n# Adding title and labels\nplt.title('Total Renewable Energy Consumption by Season')\nplt.ylabel('Total Renewable Energy Consumption')\nplt.xlabel('Season')\n\n\nplt.text(0.5, 0.5, \"Kaggle Notebook by Mohsin Ali\", \n         fontsize=30, color='gray', alpha=0.3, \n         ha='center', va='center', rotation=30, transform=ax.transAxes)\n\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T18:18:47.324791Z","iopub.execute_input":"2024-12-27T18:18:47.325229Z","iopub.status.idle":"2024-12-27T18:18:47.618155Z","shell.execute_reply.started":"2024-12-27T18:18:47.325201Z","shell.execute_reply":"2024-12-27T18:18:47.616770Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Creating a month-season mapping for each row\nmonth_season_data = data.groupby(['Year', 'Month']).agg({\n    'Total Renewable Energy': 'mean',\n    'Season_Spring': 'first',\n    'Season_Summer': 'first',\n    'Season_Winter': 'first'\n}).reset_index()\n\n# Assigning seasons based on the binary columns\nmonth_season_data['Season'] = month_season_data.apply(\n    lambda row: 'Spring' if row['Season_Spring'] else \n                ('Summer' if row['Season_Summer'] else 'Winter'), axis=1\n)\n\n# Ploting the data\nplt.figure(figsize=(8, 4))\nax = sns.lineplot(data=month_season_data, x='Month', y='Total Renewable Energy', hue='Season', \n                  style='Season', markers=True, palette='viridis')\n\n# Add titles and labels\nplt.title('Monthly Renewable Energy Consumption by Season')\nplt.xlabel('Month')\nplt.ylabel('Total Renewable Energy Consumption')\n\n\nplt.text(0.5, 0.5, \"Kaggle Notebook by Mohsin ALi\", \n         fontsize=30, color='gray', alpha=0.3, \n         ha='center', va='center', rotation=30, transform=ax.transAxes)\n\n\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T18:20:12.680302Z","iopub.execute_input":"2024-12-27T18:20:12.680757Z","iopub.status.idle":"2024-12-27T18:20:13.522690Z","shell.execute_reply.started":"2024-12-27T18:20:12.680726Z","shell.execute_reply":"2024-12-27T18:20:13.521675Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Creating a pivot table for 'Total Renewable Energy' by 'Year' and 'Month'\npivot_data = data.pivot_table(values='Total Renewable Energy', index='Year', columns='Month', aggfunc='mean')\n\n# Ploting the heatmap\nplt.figure(figsize=(8, 5))\nax = sns.heatmap(pivot_data, cmap='YlGnBu', annot=False, cbar_kws={'label': 'Total Renewable Energy'})\n\n# Adding titles and labels\nplt.title('Seasonal Renewable Energy Consumption Heatmap')\nplt.xlabel('Month')\nplt.ylabel('Year')\n\n\nplt.text(0.5, 0.5, \"Kaggle Notebook by Mohsin Ali\", \n         fontsize=30, color='gray', alpha=0.3, \n         ha='center', va='center', rotation=30, transform=ax.transAxes)\n\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T18:21:14.470393Z","iopub.execute_input":"2024-12-27T18:21:14.470852Z","iopub.status.idle":"2024-12-27T18:21:15.038403Z","shell.execute_reply.started":"2024-12-27T18:21:14.470817Z","shell.execute_reply":"2024-12-27T18:21:15.036871Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 5: Building Random Forest Model","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nimport pandas as pd\nimport numpy as np\n\n# Step 1: Preparing the data\n# Converting categorical features to numeric (excluding 'Sector' as it's the target)\ndata_encoded = pd.get_dummies(data.drop(columns=['Sector']), drop_first=True)\nX = data_encoded  # Features\ny = data['Sector']  # Target variable\n\n# Step 2: Spliting the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Step 3: Training the Random Forest model\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_model.fit(X_train, y_train)\n\n# Step 4: Making predictions on the test set\ny_pred_rf = rf_model.predict(X_test)\n\n# Step 5: Evaluating the model on the test set\nprint(\"Random Forest Model Performance on Test Set:\")\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\nprint(\"Classification Report:\")\nprint(classification_report(y_test, y_pred_rf))\n\n# Step 6: Performing 5-fold cross-validation for different evaluation metrics\naccuracy_scores_rf = cross_val_score(rf_model, X, y, cv=5, scoring='accuracy')\nprecision_scores_rf = cross_val_score(rf_model, X, y, cv=5, scoring='precision_macro')\nrecall_scores_rf = cross_val_score(rf_model, X, y, cv=5, scoring='recall_macro')\nf1_scores_rf = cross_val_score(rf_model, X, y, cv=5, scoring='f1_macro')\n\n# Step 7: Printing the average scores and standard deviations for cross-validation\nprint(\"\\n5-Fold Cross-Validation Results for Random Forest:\")\nprint(\"Accuracy: {:.2f} ± {:.2f}\".format(np.mean(accuracy_scores_rf), np.std(accuracy_scores_rf)))\nprint(\"Precision: {:.2f} ± {:.2f}\".format(np.mean(precision_scores_rf), np.std(precision_scores_rf)))\nprint(\"Recall: {:.2f} ± {:.2f}\".format(np.mean(recall_scores_rf), np.std(recall_scores_rf)))\nprint(\"F1 Score: {:.2f} ± {:.2f}\".format(np.mean(f1_scores_rf), np.std(f1_scores_rf)))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T18:22:52.412204Z","iopub.execute_input":"2024-12-27T18:22:52.412657Z","iopub.status.idle":"2024-12-27T18:22:59.029422Z","shell.execute_reply.started":"2024-12-27T18:22:52.412616Z","shell.execute_reply":"2024-12-27T18:22:59.028162Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 5: Building SVM Model","metadata":{}},{"cell_type":"code","source":"#SVM Model \nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, classification_report\nimport numpy as np\n\n# Step 1: Prepare the data (reusing `data_encoded` from Random Forest step)\nX_SVM = data_encoded  # Features\ny_SVM = data['Sector']  # Target variable\n\n# Step 2: Split the data into training and testing sets\nX_train_SVM, X_test_SVM, y_train_SVM, y_test_SVM = train_test_split(X_SVM, y_SVM, test_size=0.2, random_state=42)\n\n# Step 3: Standardize the feature set (SVM works better with scaled features)\nscaler = StandardScaler()\nX_train_SVM = scaler.fit_transform(X_train_SVM)\nX_test_SVM = scaler.transform(X_test_SVM)\n\n# Step 4: Hyperparameter tuning with GridSearchCV\n# Defining the parameter grid\nparam_grid = {\n    'C': [0.1, 1, 10, 100],\n    'kernel': ['linear', 'rbf', 'poly'],\n    'gamma': ['scale', 'auto']\n}\n\n# Initialize the SVM model\nsvm_model = SVC()\n\n# Initialize GridSearchCV\ngrid_search_SVM = GridSearchCV(svm_model, param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n\n# Fit the model to find the best parameters\ngrid_search_SVM.fit(X_train_SVM, y_train_SVM)\n\n# Step 5: Get the best estimator from GridSearchCV\nbest_svm_model = grid_search_SVM.best_estimator_\nprint(\"Best SVM parameters:\", grid_search_SVM.best_params_)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T18:26:33.418115Z","iopub.execute_input":"2024-12-27T18:26:33.418476Z","iopub.status.idle":"2024-12-27T18:26:39.230995Z","shell.execute_reply.started":"2024-12-27T18:26:33.418451Z","shell.execute_reply":"2024-12-27T18:26:39.229697Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Step 6: Evaluating the best model on the test set\ny_pred_SVM = best_svm_model.predict(X_test_SVM)\nprint(\"\\nSVM Model Performance on Test Set:\")\nprint(\"Accuracy:\", accuracy_score(y_test_SVM, y_pred_SVM))\nprint(\"Classification Report:\\n\", classification_report(y_test_SVM, y_pred_SVM))\n\n# Step 7: Cross-Validation with the best model\nfrom sklearn.model_selection import cross_val_score\n\n# Perforing 5-fold cross-validation for different evaluation metrics\naccuracy_scores_SVM = cross_val_score(best_svm_model, X_SVM, y_SVM, cv=5, scoring='accuracy')\nprecision_scores_SVM = cross_val_score(best_svm_model, X_SVM, y_SVM, cv=5, scoring='precision_macro')\nrecall_scores_SVM = cross_val_score(best_svm_model, X_SVM, y_SVM, cv=5, scoring='recall_macro')\nf1_scores_SVM = cross_val_score(best_svm_model, X_SVM, y_SVM, cv=5, scoring='f1_macro')\n\n# Printing the average scores and standard deviations\nprint(\"\\n5-Fold Cross-Validation Results for SVM:\")\nprint(\"Accuracy: {:.2f} ± {:.2f}\".format(np.mean(accuracy_scores_SVM), np.std(accuracy_scores_SVM)))\nprint(\"Precision: {:.2f} ± {:.2f}\".format(np.mean(precision_scores_SVM), np.std(precision_scores_SVM)))\nprint(\"Recall: {:.2f} ± {:.2f}\".format(np.mean(recall_scores_SVM), np.std(recall_scores_SVM)))\nprint(\"F1 Score: {:.2f} ± {:.2f}\".format(np.mean(f1_scores_SVM), np.std(f1_scores_SVM)))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T18:27:05.116795Z","iopub.execute_input":"2024-12-27T18:27:05.117191Z","iopub.status.idle":"2024-12-27T18:27:14.467783Z","shell.execute_reply.started":"2024-12-27T18:27:05.117164Z","shell.execute_reply":"2024-12-27T18:27:14.466710Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 6: Comparative Analysis","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom math import pi\n\n# Step 1: Prepare the data\nmetrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\nnum_metrics = len(metrics)\n\n# Calculate the average cross-validation scores for both models\nrf_scores = [np.mean(accuracy_scores_rf), np.mean(precision_scores_rf), np.mean(recall_scores_rf), np.mean(f1_scores_rf)]\nsvm_scores = [np.mean(accuracy_scores_SVM), np.mean(precision_scores_SVM), np.mean(recall_scores_SVM), np.mean(f1_scores_SVM)]\n\n# Step 2: Prepare the radar chart\nangles = [n / float(num_metrics) * 2 * pi for n in range(num_metrics)]\nangles += angles[:1]  # Complete the loop\n\n# Append the first value to the end of each score list for radar chart closure\nrf_scores += rf_scores[:1]\nsvm_scores += svm_scores[:1]\n\n# Step 3: Plot the radar chart\nplt.figure(figsize=(5, 5))\nax = plt.subplot(111, polar=True)\n\n# Draw one axe per variable + add labels\nplt.xticks(angles[:-1], metrics)\n\n# Plot each model's data\nax.plot(angles, rf_scores, label=\"Random Forest\", color='b', linewidth=2, linestyle='-')\nax.fill(angles, rf_scores, color='b', alpha=0.25)\n\nax.plot(angles, svm_scores, label=\"SVM\", color='r', linewidth=2, linestyle='--')\nax.fill(angles, svm_scores, color='r', alpha=0.25)\n\n# Step 4: Add a title and legend\nplt.title(\"Performance Comparison of Random Forest and SVM Models\", size=15, color='black', pad=20)\nplt.legend(loc='upper right', bbox_to_anchor=(1.1, 1.1))\n\n# Step 5: Add watermark\nplt.text(0.5, 0.5, \"Kaggle Notebook by Mohsin ALi\", \n         fontsize=30, color='gray', alpha=0.3, \n         ha='center', va='center', rotation=30, \n         transform=ax.transAxes)\n\n# Display the radar chart\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T18:30:13.174487Z","iopub.execute_input":"2024-12-27T18:30:13.175013Z","iopub.status.idle":"2024-12-27T18:30:13.701440Z","shell.execute_reply.started":"2024-12-27T18:30:13.174975Z","shell.execute_reply":"2024-12-27T18:30:13.699754Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\n# Mean and standard deviation for Random Forest (from cross-validation)\nrf_means = [np.mean(accuracy_scores_rf), np.mean(precision_scores_rf), np.mean(recall_scores_rf), np.mean(f1_scores_rf)]\nrf_stds = [np.std(accuracy_scores_rf), np.std(precision_scores_rf), np.std(recall_scores_rf), np.std(f1_scores_rf)]\n\n# Mean and standard deviation for SVM (from cross-validation)\nsvm_means = [np.mean(accuracy_scores_SVM), np.mean(precision_scores_SVM), np.mean(recall_scores_SVM), np.mean(f1_scores_SVM)]\nsvm_stds = [np.std(accuracy_scores_SVM), np.std(precision_scores_SVM), np.std(recall_scores_SVM), np.std(f1_scores_SVM)]\n\n# Labels for the metrics\nmetrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\nx = np.arange(len(metrics))  # X-axis positions for the metrics\n\n# Bar width\nwidth = 0.35  \n\n# Create the plot\nplt.figure(figsize=(6, 4))\n\n# Bar for Random Forest\nplt.bar(x - width/2, rf_means, width, yerr=rf_stds, capsize=5, label='Random Forest', color='skyblue', alpha=0.8)\n\n# Bar for SVM\nplt.bar(x + width/2, svm_means, width, yerr=svm_stds, capsize=5, label='SVM', color='salmon', alpha=0.8)\n\n\nplt.xticks(x, metrics)\nplt.ylabel('Scores')\nplt.title('Comparison of Random Forest and SVM Models (5-Fold Cross-Validation)')\nplt.legend()\nplt.grid(axis='y', linestyle='--', alpha=0.7)\n\n\nplt.text(0.5, 0.5, \"Kaggle Notebook by Mohsin Ali\", \n         fontsize=30, color='gray', alpha=0.3, \n         ha='center', va='center', rotation=30, \n         transform=plt.gca().transAxes)\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T18:31:18.317489Z","iopub.execute_input":"2024-12-27T18:31:18.318091Z","iopub.status.idle":"2024-12-27T18:31:18.704936Z","shell.execute_reply.started":"2024-12-27T18:31:18.318055Z","shell.execute_reply":"2024-12-27T18:31:18.703734Z"}},"outputs":[],"execution_count":null}]}